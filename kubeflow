

https://github.com/kubeflow/kubeflow/blob/master/user_guide.md



Using Kubeflow
This guide will walk you through the basics of deploying and interacting with Kubeflow. Some understanding of Kubernetes, Tensorflow, and Ksonnet are useful in completing the contents of this guide.

Kubernetes
Tensorflow
Ksonnet
Requirements
Kubernetes >= 1.8 see here
ksonnet version 0.8.0 or later. (See below for an explanation of why we use ksonnet)


Deploy Kubeflow
We will be using Ksonnet to deploy kubeflow into your cluster.

Initialize a directory to contain your ksonnet application.

ks init my-kubeflow --api-spec=version:v1..0

Install the Kubeflow packages into your application.

cd /ks/my-kubeflow
ks registry add kubeflow github.com/kubeflow/kubeflow/tree/master/kubeflow
ks pkg install kubeflow/core
ks pkg install kubeflow/tf-serving
ks pkg install kubeflow/tf-job


Create the Kubeflow core component. The core component includes

JupyterHub
TensorFlow job controller

NAMESPACE=kube-flow
kubectl create namespace ${NAMESPACE}
ks generate core kubeflow-core --name=kubeflow-core --namespace=${NAMESPACE}

Ksonnet allows us to parameterize the Kubeflow deployment according to our needs. We will define two environments: nocloud, and cloud.

ks env add nocloud
ks env add cloud

Now let's set ${KF_ENV} to cloud or nocloud to reflect our environment for the rest of the guide:

$ KF_ENV=nocloud

And apply the components to our Kubernetes cluster

ks env add kubeflow29
KF_ENV=kubeflow29

ks apply ${KF_ENV} -c kubeflow-core

At any time you can inspect the kubernetes objects definitions for a particular ksonnet component using ks show e.g

ks show ${KF_ENV} -c kubeflow-core

Bringing up a Notebook
The kubeflow-core component deployed JupyterHub and a corresponding load balancer service. You can check its status using the kubectl command line.

kubectl get svc -n=kubeflow

kubectl get po -n=kubeflow

To connect to your notebook:

PODNAME=`kubectl get pods --namespace=kubeflow --selector="app=tf-hub" --output=template --template="{{with index .items 0}}{{.metadata.name}}{{end}}"`

kubectl port-forward --namespace=${NAMESPACE} $PODNAME 8000:8000
Then open http://127.0.0.1:8000 in your browser.


# kubectl apply -f /home/k8s/ingress/tf-hub-ingress.yaml

https://tf-hub.myth.tech


You should see a sign in prompt.

1.Sign in using any username/password
2.Click the "Start My Server" button, you will be greeted by a dialog screen.
3.Set the image to gcr.io/kubeflow/tensorflow-notebook-cpu:v1 or gcr.io/kubeflow/tensorflow-notebook-gpu:8fbc341245695e482848ac3c2034a99f7c1e5763 depending on whether doing CPU or GPU training, or whether or not you have GPUs in your cluster.
4.Allocate memory, CPU, GPU, or other resources according to your need (1 CPU and 2Gi of Memory are good starting points)
To allocate GPUs, make sure that you have GPUs available in your cluster
Run the following command to check if there are any nvidia gpus available: kubectl get nodes "-o=custom-columns=NAME:.metadata.name,GPU:.status.allocatable.nvidia\.com/gpu"
If you have GPUs available, you can schedule your server on a GPU node by specifying the following json in Extra Resource Limits section: {"nvidia.com/gpu": "1"}
5.Click Spawn
6.Eventually you should now be greeted with a Jupyter interface. Note that the GPU image is several gigabytes in size and may take a few minutes to download and start.






Serve a model
We treat each deployed model as a component in your APP.

Create a component for your model

MODEL_COMPONENT=serveInception
MODEL_NAME=inception
MODEL_PATH=gs://kubeflow-models/inception

ks generate tf-serving ${MODEL_COMPONENT} --name=${MODEL_NAME} --namespace=${NAMESPACE} --model_path=${MODEL_PATH}

ks show ${KF_ENV} -c inception

ks apply ${KF_ENV} -c ${MODEL_COMPONENT}

kubectl get svc inception -n=${NAMESPACE}


Serve a model using Seldon
Seldon-core provides deployment for any machine learning runtime that can be packaged in a Docker container.

Install the seldon package

ks pkg install kubeflow/seldon
Generate the core components

ks generate seldon seldon



Submiting a TensorFlow training job
Note: Before submitting a training job, you should have deployed kubeflow to your cluster. Doing so ensures that the TFJob custom resource is available when you submit the training job.

We treat each TensorFlow job as a component in your APP.

Create a component for your job.

JOB_NAME=myjob
ks generate tf-job ${JOB_NAME} --name=${JOB_NAME} --namespace=${NAMESPACE}
To configure your job you need to set a bunch of parameters. To see a list of parameters run

ks prototype describe tf-job
Parameters can be set using ks param e.g. to set the Docker image used

IMAGE=rimages:5000/kubespray2.3/tf_sample:d4ef871-dirty-991dde4

ks param set ${JOB_NAME} image ${IMAGE}





Run the TfCnn example
Kubeflow ships with a ksonnet prototype suitable for running the TensorFlow CNN Benchmarks.

Create the component

CNN_JOB_NAME=mycnnjob
ks generate tf-cnn ${CNN_JOB_NAME} --name=${CNN_JOB_NAME} --namespace=kubeflow

Submit it

ks apply ${KF_ENV} -c ${CNN_JOB_NAME}

The prototype provides a bunch of parameters to control how the job runs (e.g. use GPUs run distributed etc...). To see a list of paramets

ks prototype describe tf-cnn





http_proxy_image: "gcr.io/kubeflow/http-proxy:1.0",
model_server_image: "gcr.io/kubeflow/model-server:1.0",

docker pull mythmoon/http-proxy:1.0

docker pull mythmoon/model-server:1.0

image: gcr.io/kubeflow/jupyterhub-k8s:1.0.1

docker pull registry.cn-hangzhou.aliyuncs.com/seder/kubeflow-jupyterhub:1.0

image: gcr.io/tf-on-k8s-dogfood/tf_operator:v20180131-cabc1c0-dirty-e3b0c44
  
docker pull registry.cn-hangzhou.aliyuncs.com/fennudehaogua/flow1
 
image: quay.io/datawire/ambassador:0.26.0
 
docker pull quay.io/datawire/ambassador:0.26.0
 
- image: quay.io/datawire/statsd:0.22.0 

docker pull quay.io/datawire/statsd:0.22.0 

gcr.io/kubeflow/tensorflow-notebook-cpu:v1 or gcr.io/kubeflow/tensorflow-notebook-gpu:8fbc341245695e482848ac3c2034a99f7c1e5763 



docker tag  11.85.198.36:5000/kubespray2.3/tf_operator:v20180131-cabc1c0-dirty-e3b0c44  rimages:5000/kubespray2.3/tf_operator:v20180131-cabc1c0-dirty-e3b0c44

docker tag mythmoon/gcr.io:1.01  rimages:5000/kubespray2.3/jupyterhub-k8s:1.0.1

docker tag quay.io/datawire/ambassador:0.26.0 rimages:5000/kubespray2.3/ambassador:0.26.0

docker tag quay.io/datawire/statsd:0.22.0  rimages:5000/kubespray2.3/statsd:0.22.0

docker save -o kubeflow.tar rimages:5000/kubespray2.3/tf_operator:v20180131-cabc1c0-dirty-e3b0c44 rimages:5000/kubespray2.3/kubeflow-jupyterhub:1.0 rimages:5000/kubespray2.3/ambassador:0.26.0 rimages:5000/kubespray2.3/statsd:0.22.0 

docker load -i kubeflow.tar

docker push  rimages:5000/kubespray2.3/tf_operator:v20180131-cabc1c0-dirty-e3b0c44

docker push rimages:5000/kubespray2.3/kubeflow-jupyterhub:1.0

docker push rimages:5000/kubespray2.3/ambassador:0.26.0

docker push  rimages:5000/kubespray2.3/statsd:0.22.0


docker save -o jupyterhub-k8s_1.0.1.tar rimages:5000/kubespray2.3/jupyterhub-k8s:1.0.1

docker load -i jupyterhub-k8s_1.0.1.tar

docker push rimages:5000/kubespray2.3/jupyterhub-k8s:1.0.1


docker pull mythmoon/tensorflow-notebook-cpu:v1

docker pull mythmoon/tensorflow-notebook-gpu:8fbc341245695e482848ac3c2034a99f7c1e5763 

docker pull mythmoon/http-proxy:1.0

docker pull mythmoon/model-server:1.0

docker pull mythmoon/tf_sample:d4ef871-dirty-991dde4

docker tag mythmoon/http-proxy:1.0 rimages:5000/kubespray2.3/http-proxy:1.0

docker tag mythmoon/model-server:1.0 rimages:5000/kubespray2.3/model-server:1.0

docker tag mythmoon/tensorflow-notebook-cpu:v1 rimages:5000/kubespray2.3/tensorflow-notebook-cpu:v1

docker tag mythmoon/tensorflow-notebook-gpu:8fbc341245695e482848ac3c2034a99f7c1e5763  rimages:5000/kubespray2.3/tensorflow-notebook-gpu:8fbc341245695e482848ac3c2034a99f7c1e5763 

docker tag mythmoon/tf_sample:d4ef871-dirty-991dde4 rimages:5000/kubespray2.3/tf_sample:d4ef871-dirty-991dde4

docker save -o tensorflow-notebook1.tar rimages:5000/kubespray2.3/tensorflow-notebook-cpu:v1

docker save -o http-model.tar rimages:5000/kubespray2.3/http-proxy:1.0 rimages:5000/kubespray2.3/model-server:1.0 

docker save -o tf_sample.tar rimages:5000/kubespray2.3/tf_sample:d4ef871-dirty-991dde4

docker save -o tensorflow-notebook2.tar rimages:5000/kubespray2.3/tensorflow-notebook-gpu:8fbc341245695e482848ac3c2034a99f7c1e5763 

docker load -i tensorflow-notebook1.tar

docker load -i tensorflow-notebook2.tar

docker load -i http-model.tar

docker load -i tf_sample.tar

docker push rimages:5000/kubespray2.3/http-proxy:1.0

docker push rimages:5000/kubespray2.3/model-server:1.0

docker push rimages:5000/kubespray2.3/tensorflow-notebook-cpu:v1

docker push rimages:5000/kubespray2.3/tensorflow-notebook-gpu:8fbc341245695e482848ac3c2034a99f7c1e5763 
 
docker push rimages:5000/kubespray2.3/tf_sample:d4ef871-dirty-991dde4

